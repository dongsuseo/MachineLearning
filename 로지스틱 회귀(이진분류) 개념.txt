로지스틱 회귀

knn분류와 비슷하게 확률 기반으로 데이터를 분류한다
선형회귀와 비슷하게 선형 방정식을 사용하여 데이터를 분류한다
여러 특징을 사용할 경우 다중회귀와 비슷하다
데이터가 어떤 클래스에 속할 확률을 0과 1사이의 수로 계산하여, 높은 확률의 클래스로 분류
----------------------------------------------------------------------------------------------------
로지스틱 함수

확률을 0과 1사이의 수로 변환하기 위하여 시그모이드 함수를 사용한다.
선형 방정식의 결과값이 큰 음수 일 경우 0으로 근접하고, 큰 양수일 경우 1로 근접한다.

import numpy as np
import matplotlib.pyplot as plt
z = np.arrange(-10, 10, 0.1)
y = 1 / (1+np.exp(-z))
plt.plot(z,y)
plt.title('sigmoid'); plt.xlabel('z'); plt.ylabel('y')
plt.show()
----------------------------------------------------------------------------------------------------
엔트로피

불확실성, 무질서도, 새로운 정보량, 놀라움 등의 정도를 나타내는 값
발생확률이 낮은 사건일수록, 정보량이 높다
엔트로피가 클수록, 데이터가 불확실하고 무질서하여 데이터가 잘 분리되어 있지 않은 상태
엔트로피가 작을수록, 데이터가 잘 분리되어 있는 상태
엔트로피는 정보의 기댓값, 평균 정보량으로 계산
I = p(x)(-log(px))    //   p(x) : 실제확률 ,  -log(p(x)) : 정보량
----------------------------------------------------------------------------------------------------
교차-엔트로피(Cross-Entropy) 손실함수

로지스틱회귀 모델에서 사용하는 손실함수를 위해 크로스 엔트로피 공식 사용
엔트로피에서의 실제(정답) 확률 값만 사용하는 대신에, 크로스 엔트로피에서는 예측 확률값 사용
정보량 = 실제값과 예측값이 얼마나 근사한지의 정도
L = -ylog(y') - (1-y)log(1-y')

